{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Charu-Mittal12/Person_tracking_and_detection/blob/main/person_detection_and_Tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRbmIZ4mKXNz",
        "outputId": "626b1895-7566-4dc6-8d4c-eee25b1aec67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting deep_sort_realtime\n",
            "  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deep_sort_realtime) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from deep_sort_realtime) (1.11.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from deep_sort_realtime) (4.8.0.76)\n",
            "Downloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep_sort_realtime\n",
            "Successfully installed deep_sort_realtime-1.3.2\n"
          ]
        }
      ],
      "source": [
        "pip install deep_sort_realtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5TsacIgfz59"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "from vidgear.gears import CamGear\n",
        "import dlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLq3vA77gkiw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHGuAT6PgoCB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUclAH9kf5SI",
        "outputId": "8eb6618b-182f-4363-e1a8-8f11a56b8883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m15:55:45\u001b[0m :: \u001b[1;35m   Helper    \u001b[0m :: \u001b[1;33m DEBUG  \u001b[0m :: \u001b[1;37mSelecting `best` resolution for streams.\u001b[0m\n",
            "\u001b[32m15:55:45\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;36m  INFO  \u001b[0m :: \u001b[1;37mVerifying Streaming URL using yt-dlp backend. Please wait...\u001b[0m\n",
            "\u001b[32m15:55:47\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;36m  INFO  \u001b[0m :: \u001b[1;37m[Backend] :: Streaming URL is fully supported. Available Streams are: [best, worst]\u001b[0m\n",
            "\u001b[32m15:55:47\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;33m DEBUG  \u001b[0m :: \u001b[1;37mUsing `best` resolution for streaming.\u001b[0m\n",
            "\u001b[32m15:55:47\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;33m DEBUG  \u001b[0m :: \u001b[1;37mYouTube source ID: `aulLej6Z6W8`, Title: `Matching`, Quality: `best`\u001b[0m\n",
            "\u001b[32m15:55:47\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;33m DEBUG  \u001b[0m :: \u001b[1;37mEnabling Threaded Queue Mode for the current video source!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load an official or custom model\n",
        "model = YOLO('yolov8l-pose.pt')  # Load an official Detect model\n",
        "\n",
        "# Open the saved video\n",
        "cap = CamGear(source='https://www.youtube.com/watch?v=aulLej6Z6W8',stream_mode =True, logging = True).start()\n",
        "tracker = DeepSort(nms_max_overlap=1,max_cosine_distance=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "090VAxI7KyGz"
      },
      "outputs": [],
      "source": [
        "# Initialize VideoWriter\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Codec (XVID is a popular choice)\n",
        "#output_file = 'output_video.avi'  # Output video file name\n",
        "fps = 30  # Frames per second (adjust if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR18RCNEKQz4",
        "outputId": "9e1bcc0e-4b49-4ed0-b8dd-91a41ee2252a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGLupgLFKWYX"
      },
      "outputs": [],
      "source": [
        "output_file = '/content/drive/My Drive/output_video1.avi'\n",
        "# Get the frame size from the underlying stream object\n",
        "frame_size = (int(cap.stream.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.stream.get(cv2.CAP_PROP_FRAME_HEIGHT)))  # Frame size\n",
        "\n",
        "out = cv2.VideoWriter(output_file, fourcc, fps, frame_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pzLspTsKBY5",
        "outputId": "cebfcea4-42cc-449f-e397-010728d36e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m16:04:09\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;33m DEBUG  \u001b[0m :: \u001b[1;37mTerminating processes.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "checkpoint_dir = '/content/drive/My Drive/checkpoints/'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "frame_count = 0\n",
        "checkpoint_interval = 300  # Save every 300 frames\n",
        "\n",
        "while True:\n",
        "    frame = cap.read()\n",
        "\n",
        "    if frame is None:\n",
        "        break  # Exit loop if no more frames\n",
        "\n",
        "    # Detect persons using YOLO\n",
        "    results = model(frame)[0]\n",
        "    detected_boxes = []\n",
        "    id = []\n",
        "    for result in results.boxes.data.tolist():\n",
        "        x1, y1, x2, y2, score, class_id = result\n",
        "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
        "        if class_id == 0:\n",
        "            detected_boxes.append(([x1, y1, x2, y2], score, class_id))\n",
        "\n",
        "    # Track objects\n",
        "    tracks = tracker.update_tracks(detected_boxes, frame=frame)\n",
        "\n",
        "    # Draw tracking IDs\n",
        "    for track in tracks:\n",
        "        track_id = track.track_id\n",
        "        id.append([track_id, track])\n",
        "        bbox = track.to_tlbr()\n",
        "        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 0, 255), 2)\n",
        "        cv2.putText(frame, f'ID: {track_id}', (int(bbox[0]), int(bbox[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
        "\n",
        "    # Write the frame to the output video\n",
        "    out.write(frame)\n",
        "\n",
        "    # Save a checkpoint frame\n",
        "    if frame_count % checkpoint_interval == 0:\n",
        "        checkpoint_file = os.path.join(checkpoint_dir, f'frame_{frame_count}.jpg')\n",
        "        cv2.imwrite(checkpoint_file, frame)\n",
        "\n",
        "    # Display the frame using cv2_imshow\n",
        "    cv2_imshow(frame)\n",
        "    time.sleep(1 / 30)  # Adjust sleep to match video frame rate if necessary\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "# Release the video capture object\n",
        "cap.stop()\n",
        "out.release()\n",
        "\n",
        "# Clean up\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLnaK4h9MNpb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP0Yxe4XhwHIhtuLOmSHrvJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}